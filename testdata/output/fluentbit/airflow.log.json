[
  {
    "logId": "py-airflow-worker-1",
    "container": "fake-container",
    "hostname": "fake-fluent",
    "labels": {
      "metadata.app": "fluent-pipeline-test",
      "metadata.app.kubernetes.io/version": "0.1.0"
    },
    "level": "INFO",
    "log": "[2023-03-01 11:15:50 +0000] [48] [INFO] [logId=py-airflow-worker-1] Booting worker with pid: 48\n\n -------------- celery@airflow-worker-0 v5.2.7 (dawn-chorus)\n--- ***** -----\n-- ******* ---- Linux-5.4.0-125-generic-x86_64-with-glibc2.31 2023-03-01 11:15:51\n- *** --- * ---\n- ** ---------- [config]\n- ** ---------- .\u003e app:         airflow.executors.celery_executor:0x7f0f5ee57a00\n- ** ---------- .\u003e transport:   redis://default:**@airflow.redis.svc:6379/2\n- ** ---------- .\u003e results:     postgresql://airflowdb:**@pg-patroni.postgres.svc:5432/airflowdb222\n- *** --- * --- .\u003e concurrency: 16 (prefork)\n-- ******* ---- .\u003e task events: OFF (enable -E to monitor tasks in this worker)\n--- ***** -----\n -------------- [queues]\n                .\u003e default          exchange=default(direct) key=default\n\n\n[tasks]\n  . airflow.executors.celery_executor.execute_command\n\n",
    "namespace": "fake-namespace",
    "nodename": "fake-node",
    "pod": "fake-fluent-577d48c6cb-4gfmp",
    "time": "2023-03-01T11:15:50.903007468Z"
  },
  {
    "logId": "py-airflow-worker-2",
    "container": "fake-container",
    "hostname": "fake-fluent",
    "labels": {
      "metadata.app": "fluent-pipeline-test",
      "metadata.app.kubernetes.io/version": "0.1.0"
    },
    "level": "info",
    "level_unknown": "true",
    "log": "[2023-03-01 11:15:56,472: INFO/MainProcess] Connected to redis://default:**@airflow.redis.svc:6379/2 [logId=py-airflow-worker-2]",
    "namespace": "fake-namespace",
    "nodename": "fake-node",
    "pod": "fake-fluent-577d48c6cb-4gfmp",
    "time": "2023-03-01T11:15:56.472007468Z"
  },
  {
    "logId": "py-airflow-worker-3",
    "container": "fake-container",
    "hostname": "fake-fluent",
    "labels": {
      "metadata.app": "fluent-pipeline-test",
      "metadata.app.kubernetes.io/version": "0.1.0"
    },
    "level": "info",
    "level_unknown": "true",
    "log": "[2023-03-01 11:16:20,697: INFO/ForkPoolWorker-15] Running \u003cTaskInstance: DR_SYNC_DAG_V2.find_correct_ssh_host manual__2023-03-01T11:16:16.045216+00:00 [queued]\u003e on host airflow-worker-0.airflow-worker.airflow.svc.cluster.local [logId=py-airflow-worker-3]\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,056] {taskinstance.py:1083} INFO - Dependencies all met for \u003cTaskInstance: DR_SYNC_DAG_V2.find_correct_ssh_host manual__2023-03-01T11:16:16.045216+00:00 [queued]\u003e\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,079] {taskinstance.py:1083} INFO - Dependencies all met for \u003cTaskInstance: DR_SYNC_DAG_V2.find_correct_ssh_host manual__2023-03-01T11:16:16.045216+00:00 [queued]\u003e\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,080] {taskinstance.py:1279} INFO -\n--------------------------------------------------------------------------------\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,080] {taskinstance.py:1280} INFO - Starting attempt 1 of 1\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,080] {taskinstance.py:1281} INFO -\n--------------------------------------------------------------------------------\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,103] {taskinstance.py:1300} INFO - Executing \u003cTask(PythonOperator): find_correct_ssh_host\u003e on 2023-03-01 11:16:16.045216+00:00\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,114] {standard_task_runner.py:55} INFO - Started process 67 to run task\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,120] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'DR_SYNC_DAG_V2', 'find_correct_ssh_host', 'manual__2023-03-01T11:16:16.045216+00:00', '--job-id', '10', '--raw', '--subdir', 'DAGS_FOLDER/dr_sync_folderv2.py', '--cfg-path', '/tmp/tmpytyuqmai']\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:22,121] {standard_task_runner.py:83} INFO - Job 10: Subtask find_correct_ssh_host\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:24,799] {task_command.py:388} INFO - Running \u003cTaskInstance: DR_SYNC_DAG_V2.find_correct_ssh_host manual__2023-03-01T11:16:16.045216+00:00 [running]\u003e on host airflow-worker-0.airflow-worker.airflow.svc.cluster.local\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:26,830] {taskinstance.py:1507} INFO - Exporting the following env vars:\nAIRFLOW_CTX_DAG_OWNER=airflow\nAIRFLOW_CTX_DAG_ID=DR_SYNC_DAG_V2\nAIRFLOW_CTX_TASK_ID=find_correct_ssh_host\nAIRFLOW_CTX_EXECUTION_DATE=2023-03-01T11:16:16.045216+00:00\nAIRFLOW_CTX_TRY_NUMBER=1\nAIRFLOW_CTX_DAG_RUN_ID=manual__2023-03-01T11:16:16.045216+00:00\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:26,833] {base.py:73} INFO - Using connection ID 'webhdfs_dr' for task execution.\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:26,834] {webhdfs.py:75} INFO - Trying to connect to hdm-0.loki.test.org:50070\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:26,836] {webhdfs.py:79} INFO - Trying namenode hdm-0.loki.test.org\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:26,838] {client.py:192} INFO - Instantiated \u003cKerberosClient(url='http://hdm-0.loki.test.org:50070/')\u003e.\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:26,844] {client.py:320} INFO - Fetching status for '/'.\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:27,192] {webhdfs.py:95} INFO - Read operation on namenode hdm-0.loki.test.org failed with error: Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:27,193] {webhdfs.py:75} INFO - Trying to connect to hdm-1.loki.test.org:50070\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:27,195] {webhdfs.py:79} INFO - Trying namenode hdm-1.loki.test.org\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:27,196] {client.py:192} INFO - Instantiated \u003cKerberosClient(url='http://hdm-1.loki.test.org:50070/')\u003e.\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:27,196] {client.py:320} INFO - Fetching status for '/'.\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:27,893] {webhdfs.py:89} INFO - Using namenode hdm-1.loki.test.org for hook\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:28,556] {python.py:177} INFO - Done. Returned value was: None\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:29,216] {taskinstance.py:1318} INFO - Marking task as SUCCESS. dag_id=DR_SYNC_DAG_V2, task_id=find_correct_ssh_host, execution_date=20230301T111616, start_date=20230301T111622, end_date=20230301T111629\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:29,309] {local_task_job.py:208} INFO - Task exited with return code 0\n[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[DAG_ID]:'DR_SYNC_DAG_V2' [TASK_ID]:'find_correct_ssh_host' [TIMESTAMP]:'2023-03-01T11:16:16.045216+00:00' [TRY_NUMBER]:'1:[2023-03-01 11:16:30,071] {taskinstance.py:2578} INFO - 1 downstream tasks scheduled from follow-on schedule check",
    "namespace": "fake-namespace",
    "nodename": "fake-node",
    "pod": "fake-fluent-577d48c6cb-4gfmp",
    "time": "2023-03-01T11:16:20.697007468Z"
  },
  {
    "logId": "py-airflow-worker-4",
    "container": "fake-container",
    "hostname": "fake-fluent",
    "labels": {
      "metadata.app": "fluent-pipeline-test",
      "metadata.app.kubernetes.io/version": "0.1.0"
    },
    "level": "info",
    "level_unknown": "true",
    "log": "[2023-03-01 11:16:30,247: INFO/MainProcess] Task airflow.executors.celery_executor.execute_command[00000000-0000-0000-0000-000000000000] received [logId=py-airflow-worker-4]",
    "namespace": "fake-namespace",
    "nodename": "fake-node",
    "pod": "fake-fluent-577d48c6cb-4gfmp",
    "time": "2023-03-01T11:16:30.247007468Z"
  },
  {
    "logId": "py-airflow-scheduler-1",
    "container": "fake-container",
    "hostname": "fake-fluent",
    "labels": {
      "metadata.app": "fluent-pipeline-test",
      "metadata.app.kubernetes.io/version": "0.1.0"
    },
    "level": "info",
    "level_unknown": "true",
    "log": "[2023-03-08T09:57:38.903+0000] {cli_action_loggers.py:135} WARNING - Failed to log action (psycopg2.OperationalError) connection to server at \"pg-patroni.postgres.svc\" (172.30.9.242), port 5432 failed: FATAL:  password authentication failed for user \"airflowdb\"\n\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\nTraceback (most recent call last):\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 3361, in _wrap_pool_connect[logId=py-airflow-scheduler-1]\n    return fn()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 327, in connect\n    return _ConnectionFairy._checkout(self)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 894, in _checkout\n    fairy = _ConnectionRecord.checkout(pool)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 493, in checkout\n    rec = pool._do_get()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/impl.py\", line 146, in _do_get\n    self._dec_overflow()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 70, in __exit__\n    compat.raise_(\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n    raise exception\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/impl.py\", line 143, in _do_get\n    return self._create_connection()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 273, in _create_connection\n    return _ConnectionRecord(self)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 388, in __init__\n    self.__connect()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 691, in __connect\n    pool.logger.debug(\"Error on connect(): %s\", e)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 70, in __exit__\n    compat.raise_(\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n    raise exception\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 686, in __connect\n    self.dbapi_connection = connection = pool._invoke_creator(self)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/create.py\", line 578, in connect\n    return dialect.connect(*cargs, **cparams)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 598, in connect\n    return self.dbapi.connect(*cargs, **cparams)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/psycopg2/__init__.py\", line 122, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\npsycopg2.OperationalError: connection to server at \"pg-patroni.postgres.svc\" (172.30.9.242), port 5432 failed: FATAL:  password authentication failed for user \"airflowdb\"\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/airflow/.local/bin/airflow\", line 8, in \u003cmodule\u003e\n    sys.exit(main())\n  File \"/home/airflow/.local/lib/python3.9/site-packages/airflow/__main__.py\", line 39, in main\n    args.func(args)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/cli_parser.py\", line 52, in command\n    return func(*args, **kwargs)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/cli.py\", line 108, in wrapper\n    return f(*args, **kwargs)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/commands/db_command.py\", line 192, in check\n    db.check()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py\", line 75, in wrapper\n    return func(*args, session=session, **kwargs)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/db.py\", line 1720, in check\n    session.execute(\"select 1 as is_alive;\")\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/session.py\", line 1713, in execute\n    conn = self._connection_for_bind(bind)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/session.py\", line 1552, in _connection_for_bind\n    return self._transaction._connection_for_bind(\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/orm/session.py\", line 747, in _connection_for_bind\n    conn = bind.connect()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 3315, in connect\n    return self._connection_cls(self, close_with_result=close_with_result)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 96, in __init__\n    else engine.raw_connection()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 3394, in raw_connection\n    return self._wrap_pool_connect(self.pool.connect, _connection)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 3364, in _wrap_pool_connect\n    Connection._handle_dbapi_exception_noconnection(\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 2198, in _handle_dbapi_exception_noconnection\n    util.raise_(\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n    raise exception\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/base.py\", line 3361, in _wrap_pool_connect\n    return fn()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 327, in connect\n    return _ConnectionFairy._checkout(self)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 894, in _checkout\n    fairy = _ConnectionRecord.checkout(pool)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 493, in checkout\n    rec = pool._do_get()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/impl.py\", line 146, in _do_get\n    self._dec_overflow()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 70, in __exit__\n    compat.raise_(\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n    raise exception\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/impl.py\", line 143, in _do_get\n    return self._create_connection()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 273, in _create_connection\n    return _ConnectionRecord(self)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 388, in __init__\n    self.__connect()\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 691, in __connect\n    pool.logger.debug(\"Error on connect(): %s\", e)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py\", line 70, in __exit__\n    compat.raise_(\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n    raise exception\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/pool/base.py\", line 686, in __connect\n    self.dbapi_connection = connection = pool._invoke_creator(self)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/create.py\", line 578, in connect\n    return dialect.connect(*cargs, **cparams)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/sqlalchemy/engine/default.py\", line 598, in connect\n    return self.dbapi.connect(*cargs, **cparams)\n  File \"/home/airflow/.local/lib/python3.9/site-packages/psycopg2/__init__.py\", line 122, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\nsqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at \"pg-patroni.postgres.svc\" (172.30.9.242), port 5432 failed: FATAL:  password authentication failed for user \"airflowdb\"\n\n(Background on this error at: https://sqlalche.me/e/14/e3q8)\n\n",
    "namespace": "fake-namespace",
    "nodename": "fake-node",
    "pod": "fake-fluent-577d48c6cb-4gfmp",
    "time": "2023-03-08T09:57:38.903007468Z"
  }
]